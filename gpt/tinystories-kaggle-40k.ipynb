{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14073044,"sourceType":"datasetVersion","datasetId":8958219},{"sourceId":14083977,"sourceType":"datasetVersion","datasetId":8966753}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom tokenizers.trainers import BpeTrainer\nfrom tokenizers.pre_tokenizers import Whitespace","metadata":{"id":"qrewtNWm78NH","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:15.949895Z","iopub.execute_input":"2025-12-10T05:27:15.951261Z","iopub.status.idle":"2025-12-10T05:27:19.895717Z","shell.execute_reply.started":"2025-12-10T05:27:15.951214Z","shell.execute_reply":"2025-12-10T05:27:19.892554Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# --------- User configurable settings ---------\nDATA_TXT = \"/kaggle/input/tinystories40k/tinystories_train40.txt\"\nTOKENIZER_FILE = \"/kaggle/input/tinystories/tinystories_train.json\"\nMAX_CHARS = 40_000_000 # read at most 40 million characters\nVOCAB_SIZE = 4096\nBATCH_SIZE = 64\nBLOCK_SIZE = 256\nMAX_ITERS = 20000\nEVAL_INTERVAL = 200\nLEARNING_RATE = 3e-4\nEVAL_ITERS = 50 # reduced for speed during eval\nGRAD_CLIP = 1.0\n\n\n# Model size reduced to better match small dataset\nN_EMBD = 256\nN_HEAD = 4\nN_LAYER = 4\nDROPOUT = 0.1","metadata":{"id":"m5jZn3pX8W3g","outputId":"21ec8d0c-4542-4c35-f044-6e4eeb0e7a7b","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:19.897266Z","iopub.execute_input":"2025-12-10T05:27:19.897711Z","iopub.status.idle":"2025-12-10T05:27:19.904088Z","shell.execute_reply.started":"2025-12-10T05:27:19.897682Z","shell.execute_reply":"2025-12-10T05:27:19.903261Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Device (Kaggle friendly)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:19.905045Z","iopub.execute_input":"2025-12-10T05:27:19.905342Z","iopub.status.idle":"2025-12-10T05:27:19.986824Z","shell.execute_reply.started":"2025-12-10T05:27:19.905315Z","shell.execute_reply":"2025-12-10T05:27:19.986027Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"TOKENIZER_FILE = \"/kaggle/working/tokenizer.json\"\n\n# ---------------- Tokenizer (train once) ----------------\nif not os.path.exists(TOKENIZER_FILE):\n    print(\"Training tokenizer...\")\n    tokenizer = Tokenizer(BPE(unk_token='[UNK]'))\n    tokenizer.pre_tokenizer = Whitespace()\n    trainer = BpeTrainer(\n        vocab_size=VOCAB_SIZE,\n        special_tokens=['[UNK]', '[CLS]', '[SEP]', '[PAD]', '[MASK]']\n    )\n    tokenizer.train([DATA_TXT], trainer)\n\n    tokenizer.save(TOKENIZER_FILE)\n    print(\"Tokenizer saved to\", TOKENIZER_FILE)\n\nelse:\n    print(\"Loading existing tokenizer...\")\n    tokenizer = Tokenizer.from_file(TOKENIZER_FILE)\n\nvocab_size = tokenizer.get_vocab_size()\nprint(\"Vocab size:\", vocab_size)\n\nencode = lambda s: tokenizer.encode(s).ids\ndecode = lambda ids: tokenizer.decode(ids)\n","metadata":{"id":"MOkz8Kug8g_q","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:19.988845Z","iopub.execute_input":"2025-12-10T05:27:19.989288Z","iopub.status.idle":"2025-12-10T05:27:23.829666Z","shell.execute_reply.started":"2025-12-10T05:27:19.989262Z","shell.execute_reply":"2025-12-10T05:27:23.828714Z"}},"outputs":[{"name":"stdout","text":"Training tokenizer...\n\n\n\nTokenizer saved to /kaggle/working/tokenizer.json\nVocab size: 4096\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ------------ Load data ------------\nwith open(DATA_TXT, 'r', encoding='utf-8') as f:\n    text = f.read(MAX_CHARS)\n\n\ndata = torch.tensor(encode(text), dtype=torch.long)\nn = int(0.9 * len(data))\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"id":"wz4WNd_J8ipX","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:23.830512Z","iopub.execute_input":"2025-12-10T05:27:23.830726Z","iopub.status.idle":"2025-12-10T05:27:52.553385Z","shell.execute_reply.started":"2025-12-10T05:27:23.830706Z","shell.execute_reply":"2025-12-10T05:27:52.552485Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# --------------- helpers ---------------\ndef get_batch(split):\n    data_src = train_data if split == 'train' else val_data\n    ix = torch.randint(len(data_src) - BLOCK_SIZE, (BATCH_SIZE,))\n    x = torch.stack([data_src[i:i+BLOCK_SIZE] for i in ix])\n    y = torch.stack([data_src[i+1:i+BLOCK_SIZE+1] for i in ix])\n    return x.to(device), y.to(device)","metadata":{"id":"wQHG1dpu8lLW","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:52.554332Z","iopub.execute_input":"2025-12-10T05:27:52.554570Z","iopub.status.idle":"2025-12-10T05:27:52.559839Z","shell.execute_reply.started":"2025-12-10T05:27:52.554550Z","shell.execute_reply":"2025-12-10T05:27:52.559071Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss(model):\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(EVAL_ITERS)\n        for k in range(EVAL_ITERS):\n            X, Y = get_batch(split)\n            _, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean().item()\n    model.train()\n    return out","metadata":{"id":"lP0kiKRu8nQ9","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:52.560708Z","iopub.execute_input":"2025-12-10T05:27:52.560992Z","iopub.status.idle":"2025-12-10T05:27:52.579403Z","shell.execute_reply.started":"2025-12-10T05:27:52.560967Z","shell.execute_reply":"2025-12-10T05:27:52.578559Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# --------------- Rotary embeddings ---------------\nclass RotaryPositionalEmbeddings(nn.Module):\n    def __init__(self, head_dim, max_seq_len=BLOCK_SIZE):\n        super().__init__()\n        # standard RoPE inverse frequency\n        inv_freq = 10000 ** (-torch.arange(0, head_dim, 2).float() / head_dim)\n        positions = torch.arange(max_seq_len).float().unsqueeze(1)\n        angles = positions * inv_freq.unsqueeze(0) # (max_seq_len, head_dim/2)\n        # store cos and sin as buffers so they move with module.to(device)\n        self.register_buffer('cos_cached', angles.cos())\n        self.register_buffer('sin_cached', angles.sin())\n    \n    \n    def forward(self, seq_len):\n        # return slices shaped (seq_len, head_dim//2)\n        return self.cos_cached[:seq_len, :], self.sin_cached[:seq_len, :]","metadata":{"id":"KHY2Hj-y8sey","outputId":"7bb59f49-1d57-4216-b3f4-21f1cce5f08d","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:52.580253Z","iopub.execute_input":"2025-12-10T05:27:52.580519Z","iopub.status.idle":"2025-12-10T05:27:52.588713Z","shell.execute_reply.started":"2025-12-10T05:27:52.580499Z","shell.execute_reply":"2025-12-10T05:27:52.588007Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def apply_rotary_emb(x, cos, sin):\n    # x: (B, T, head_dim)\n    d = x.shape[-1] // 2\n    x1 = x[..., :d]\n    x2 = x[..., d:]\n    # cos and sin are (T, d) need to broadcast to (B, T, d)\n    # make shapes explicit for readability\n    cos = cos.unsqueeze(0)\n    sin = sin.unsqueeze(0)\n    out1 = x1 * cos - x2 * sin\n    out2 = x1 * sin + x2 * cos\n    return torch.cat([out1, out2], dim=-1)","metadata":{"id":"ZF7694hp8vIl","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:52.589448Z","iopub.execute_input":"2025-12-10T05:27:52.589668Z","iopub.status.idle":"2025-12-10T05:27:52.602659Z","shell.execute_reply.started":"2025-12-10T05:27:52.589652Z","shell.execute_reply":"2025-12-10T05:27:52.601770Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# --------------- Attention and Transformer blocks ---------------\nclass Head(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.head_size = head_size\n        self.key = nn.Linear(N_EMBD, head_size, bias=False)\n        self.query = nn.Linear(N_EMBD, head_size, bias=False)\n        self.value = nn.Linear(N_EMBD, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n        self.dropout = nn.Dropout(DROPOUT)\n        self.rotary = RotaryPositionalEmbeddings(head_size, max_seq_len=BLOCK_SIZE)\n    def forward(self, x):\n        B, T, C = x.shape\n        k = self.key(x)\n        q = self.query(x)\n        # get cos and sin for sequence length T\n        cos, sin = self.rotary(T)\n        q = apply_rotary_emb(q, cos, sin)\n        k = apply_rotary_emb(k, cos, sin)\n        # scaled dot product\n        wei = q @ k.transpose(-2, -1) * (self.head_size ** -0.5)\n        mask = self.tril[:T, :T].to(wei.device)\n        wei = wei.masked_fill(mask == 0, float('-inf'))\n        wei = F.softmax(wei, dim=-1)\n        wei = self.dropout(wei)\n        v = self.value(x)\n        out = wei @ v\n        return out\n\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(head_size * num_heads, N_EMBD)\n        self.dropout = nn.Dropout(DROPOUT)\n    \n    \n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out\n\n\nclass FeedForward(nn.Module):\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n        nn.Linear(n_embd, 4 * n_embd),\n        nn.GELU(),\n        nn.Linear(4 * n_embd, n_embd),\n        nn.Dropout(DROPOUT),\n        )\n    \n    \n    def forward(self, x):\n        return self.net(x)\n\n\nclass Block(nn.Module):\n    def __init__(self, n_embd, n_head):\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedForward(n_embd)\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n    \n    \n    def forward(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x","metadata":{"id":"HgZqyQhf8xdz","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:52.605151Z","iopub.execute_input":"2025-12-10T05:27:52.605405Z","iopub.status.idle":"2025-12-10T05:27:52.619101Z","shell.execute_reply.started":"2025-12-10T05:27:52.605387Z","shell.execute_reply":"2025-12-10T05:27:52.618280Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# --------------- GPT Model ---------------\nclass GPTLanguageModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.token_embedding_table = nn.Embedding(vocab_size, N_EMBD)\n        self.blocks = nn.Sequential(*[Block(N_EMBD, n_head=N_HEAD) for _ in range(N_LAYER)])\n        self.ln_f = nn.LayerNorm(N_EMBD)\n        self.lm_head = nn.Linear(N_EMBD, vocab_size)\n        self.apply(self._init_weights)\n    \n    \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n    \n    \n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n        tok_emb = self.token_embedding_table(idx)\n        x = tok_emb\n        x = self.blocks(x)\n        x = self.ln_f(x)\n        logits = self.lm_head(x)\n        if targets is None:\n            return logits, None\n        B, T, C = logits.shape\n        logits = logits.view(B * T, C)\n        targets = targets.view(B * T)\n        loss = F.cross_entropy(logits, targets)\n        return logits, loss\n    \n    \n    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n        for _ in range(max_new_tokens):\n            idx_cond = idx[:, -BLOCK_SIZE:]\n            logits, _ = self(idx_cond)\n            logits = logits[:, -1, :] / temperature\n            if top_k is not None:\n                v, _ = torch.topk(logits, top_k)\n                logits[logits < v[:, [-1]]] = -float('Inf')\n            probs = F.softmax(logits, dim=-1)\n            idx_next = torch.multinomial(probs, num_samples=1)\n            idx = torch.cat((idx, idx_next), dim=1)\n        return idx","metadata":{"id":"KEHv3DXi8z1G","trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:52.619912Z","iopub.execute_input":"2025-12-10T05:27:52.620200Z","iopub.status.idle":"2025-12-10T05:27:52.640822Z","shell.execute_reply.started":"2025-12-10T05:27:52.620181Z","shell.execute_reply":"2025-12-10T05:27:52.639939Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# --------------- instantiate model, optimizer, scaler ---------------\nmodel = GPTLanguageModel()\nmodel = model.to(device)\nprint(\"Model parameters: \", sum(p.numel() for p in model.parameters()) / 1e6, \"M\")\n\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\nimport torch.amp\n\nscaler = torch.amp.GradScaler(enabled=(device == 'cuda'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:52.641559Z","iopub.execute_input":"2025-12-10T05:27:52.641758Z","iopub.status.idle":"2025-12-10T05:27:56.026871Z","shell.execute_reply.started":"2025-12-10T05:27:52.641741Z","shell.execute_reply":"2025-12-10T05:27:56.026003Z"}},"outputs":[{"name":"stdout","text":"Model parameters:  5.257728 M\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"for it in range(MAX_ITERS):\n    if it % EVAL_INTERVAL == 0 or it == MAX_ITERS - 1:\n        losses = estimate_loss(model)\n        print(f\"step {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n    \n    xb, yb = get_batch('train')\n    \n    optimizer.zero_grad(set_to_none=True)\n    \n    # mixed precision when on CUDA\n    with torch.amp.autocast(device_type='cuda', enabled=(device == 'cuda')):\n        _, loss = model(xb, yb)\n    \n    if device == 'cuda':\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n        scaler.step(optimizer)\n        scaler.update()\n    else:\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n        optimizer.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T05:27:56.027777Z","iopub.execute_input":"2025-12-10T05:27:56.028132Z","iopub.status.idle":"2025-12-10T06:25:23.556966Z","shell.execute_reply.started":"2025-12-10T05:27:56.028111Z","shell.execute_reply":"2025-12-10T06:25:23.556014Z"}},"outputs":[{"name":"stdout","text":"step 0: train loss 8.3753, val loss 8.3735\nstep 200: train loss 3.6616, val loss 3.6209\nstep 400: train loss 3.1982, val loss 3.1847\nstep 600: train loss 2.9541, val loss 2.9335\nstep 800: train loss 2.7873, val loss 2.7636\nstep 1000: train loss 2.6557, val loss 2.6553\nstep 1200: train loss 2.5677, val loss 2.5682\nstep 1400: train loss 2.4832, val loss 2.4868\nstep 1600: train loss 2.4159, val loss 2.4289\nstep 1800: train loss 2.3550, val loss 2.3678\nstep 2000: train loss 2.3139, val loss 2.3503\nstep 2200: train loss 2.2620, val loss 2.3031\nstep 2400: train loss 2.2271, val loss 2.2655\nstep 2600: train loss 2.1903, val loss 2.2418\nstep 2800: train loss 2.1755, val loss 2.2241\nstep 3000: train loss 2.1407, val loss 2.1872\nstep 3200: train loss 2.1085, val loss 2.1765\nstep 3400: train loss 2.0882, val loss 2.1736\nstep 3600: train loss 2.0775, val loss 2.1477\nstep 3800: train loss 2.0524, val loss 2.1327\nstep 4000: train loss 2.0283, val loss 2.1067\nstep 4200: train loss 2.0073, val loss 2.1041\nstep 4400: train loss 2.0039, val loss 2.0952\nstep 4600: train loss 1.9783, val loss 2.0684\nstep 4800: train loss 1.9691, val loss 2.0659\nstep 5000: train loss 1.9504, val loss 2.0640\nstep 5200: train loss 1.9389, val loss 2.0591\nstep 5400: train loss 1.9320, val loss 2.0368\nstep 5600: train loss 1.9176, val loss 2.0461\nstep 5800: train loss 1.9106, val loss 2.0403\nstep 6000: train loss 1.9015, val loss 2.0206\nstep 6200: train loss 1.8882, val loss 2.0121\nstep 6400: train loss 1.8782, val loss 2.0135\nstep 6600: train loss 1.8636, val loss 2.0038\nstep 6800: train loss 1.8525, val loss 2.0003\nstep 7000: train loss 1.8583, val loss 1.9893\nstep 7200: train loss 1.8418, val loss 1.9949\nstep 7400: train loss 1.8296, val loss 2.0102\nstep 7600: train loss 1.8375, val loss 1.9903\nstep 7800: train loss 1.8330, val loss 1.9856\nstep 8000: train loss 1.8121, val loss 1.9832\nstep 8200: train loss 1.8044, val loss 1.9773\nstep 8400: train loss 1.7956, val loss 1.9705\nstep 8600: train loss 1.8005, val loss 1.9777\nstep 8800: train loss 1.7948, val loss 1.9662\nstep 9000: train loss 1.7915, val loss 1.9646\nstep 9200: train loss 1.7809, val loss 1.9594\nstep 9400: train loss 1.7613, val loss 1.9544\nstep 9600: train loss 1.7799, val loss 1.9535\nstep 9800: train loss 1.7615, val loss 1.9631\nstep 10000: train loss 1.7612, val loss 1.9565\nstep 10200: train loss 1.7465, val loss 1.9549\nstep 10400: train loss 1.7448, val loss 1.9460\nstep 10600: train loss 1.7316, val loss 1.9557\nstep 10800: train loss 1.7362, val loss 1.9469\nstep 11000: train loss 1.7376, val loss 1.9339\nstep 11200: train loss 1.7326, val loss 1.9348\nstep 11400: train loss 1.7342, val loss 1.9407\nstep 11600: train loss 1.7170, val loss 1.9461\nstep 11800: train loss 1.7278, val loss 1.9231\nstep 12000: train loss 1.7178, val loss 1.9351\nstep 12200: train loss 1.7154, val loss 1.9226\nstep 12400: train loss 1.7116, val loss 1.9304\nstep 12600: train loss 1.7043, val loss 1.9246\nstep 12800: train loss 1.6942, val loss 1.9316\nstep 13000: train loss 1.6944, val loss 1.9234\nstep 13200: train loss 1.6923, val loss 1.9309\nstep 13400: train loss 1.7001, val loss 1.9210\nstep 13600: train loss 1.6740, val loss 1.9154\nstep 13800: train loss 1.6872, val loss 1.9214\nstep 14000: train loss 1.6782, val loss 1.9073\nstep 14200: train loss 1.6858, val loss 1.9196\nstep 14400: train loss 1.6723, val loss 1.9195\nstep 14600: train loss 1.6712, val loss 1.9262\nstep 14800: train loss 1.6760, val loss 1.9086\nstep 15000: train loss 1.6667, val loss 1.9249\nstep 15200: train loss 1.6558, val loss 1.9279\nstep 15400: train loss 1.6594, val loss 1.9154\nstep 15600: train loss 1.6642, val loss 1.9090\nstep 15800: train loss 1.6517, val loss 1.9024\nstep 16000: train loss 1.6567, val loss 1.9049\nstep 16200: train loss 1.6550, val loss 1.8991\nstep 16400: train loss 1.6491, val loss 1.9106\nstep 16600: train loss 1.6438, val loss 1.9107\nstep 16800: train loss 1.6405, val loss 1.8990\nstep 17000: train loss 1.6396, val loss 1.9147\nstep 17200: train loss 1.6448, val loss 1.9038\nstep 17400: train loss 1.6296, val loss 1.8945\nstep 17600: train loss 1.6419, val loss 1.8945\nstep 17800: train loss 1.6309, val loss 1.9110\nstep 18000: train loss 1.6276, val loss 1.9088\nstep 18200: train loss 1.6281, val loss 1.9040\nstep 18400: train loss 1.6195, val loss 1.9036\nstep 18600: train loss 1.6329, val loss 1.9074\nstep 18800: train loss 1.6210, val loss 1.9077\nstep 19000: train loss 1.6133, val loss 1.9046\nstep 19200: train loss 1.6131, val loss 1.9001\nstep 19400: train loss 1.6169, val loss 1.8923\nstep 19600: train loss 1.6090, val loss 1.8985\nstep 19800: train loss 1.6128, val loss 1.9107\nstep 19999: train loss 1.6088, val loss 1.9062\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# --------------- generation example ---------------\nprint(\"Generating story...\")\nstart_prompt = \"Once upon a time\"\ncontext = torch.tensor([encode(start_prompt)], dtype=torch.long, device=device)\nwith torch.no_grad():\n    generated = model.generate(context, max_new_tokens=300, temperature=1.0, top_k=50)[0].tolist()\nprint(decode(generated))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T06:25:23.558003Z","iopub.execute_input":"2025-12-10T06:25:23.558299Z","iopub.status.idle":"2025-12-10T06:25:27.218355Z","shell.execute_reply.started":"2025-12-10T06:25:23.558270Z","shell.execute_reply":"2025-12-10T06:25:27.217615Z"}},"outputs":[{"name":"stdout","text":"Generating story...\nOnce upon a time there was a little girl called Sarah . She was very obedient and always listened to her parents . One day , her parents told her that she would always listen to her . Sarah had to do all the cho o they could do . On this day , she couldn ' t believe it ! At first , it was so strange ly dirty . Sarah had to be careful , so she picked up a pink flower and gently picked it carefully . The flower was so special . Sarah stayed put , but it remain ed the best time - until she got tired from going to a nap . Soon the sun came in the sky , and Sarah was getting better . She yaw ned in the air , and then finally closed her eyes . But Sarah was still very excited . She realized she could play so own , she just had to listen to her mom . â € œ Mommy , â € Sarah said sadly . â € œ Little W anda , that sounds like she ' s boun cy castle . â € Her mom smiled too . \" Yes , it was . Letâ €™ s do !\" Sarah and She grabbed her ball and threw it to the dog . The dog , pet ting the girl and running around . She was so happy . â € œ Now you can play with the ball ! â € she shouted . The dog just ran away with the ball . Sarah was so happy that she thanked her mom . From that day on , Sarah always looked at the steps back and made sure to stay away and remember that with a little\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# --------------- optional: save model checkpoint ---------------\nCKPT_PATH = \"tinystories_gpt.pt\"\ntry:\n    torch.save({'model_state_dict': model.state_dict(), 'tokenizer': TOKENIZER_FILE}, CKPT_PATH)\n    print(\"Saved checkpoint to\", CKPT_PATH)\nexcept Exception as e:\n    print(\"Could not save checkpoint:\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T06:25:27.219300Z","iopub.execute_input":"2025-12-10T06:25:27.219521Z","iopub.status.idle":"2025-12-10T06:25:27.275195Z","shell.execute_reply.started":"2025-12-10T06:25:27.219504Z","shell.execute_reply":"2025-12-10T06:25:27.274327Z"}},"outputs":[{"name":"stdout","text":"Saved checkpoint to tinystories_gpt.pt\n","output_type":"stream"}],"execution_count":15}]}